{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c259ec37-3498-4c60-8b9e-8cad17ac0e07",
   "metadata": {},
   "outputs": [],
   "source": [
	"# Implementation of *Automated Diagnosis of Pneumonia from Classification of Chest X-Ray Im ages using EfficientNet*\n",
	"# Reference: https://ieeexplore.ieee.org/abstract/document/9397055\n\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB2\n",
    "from tensorflow.keras.layers import RandomFlip,GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39cd456-0a81-4386-90bf-4af737796561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
	"# dataset URL: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\n",
    "base_path = 'G:\\Chest X-Ray Images (Pneumonia)\\chest_xray'\n",
    "\n",
    "data = []\n",
    "for path in ['/train', '/test', '/val']:\n",
    "    for path2 in ['/NORMAL', '/PNEUMONIA']:\n",
    "        for dirname, _, filenames in os.walk(base_path + path + path2):\n",
    "            for i, file in enumerate(filenames):\n",
    "                img_class = path2\n",
    "                data.append({'dirname': dirname, 'filename': file, 'class': img_class})\n",
    "                #data.append({'filename': file, 'class': img_class})\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Dataset has \" + str(len(df)) + \" files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca0bff0-bb6b-4393-bdaf-de5818aedb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset (60-20-20)\n",
    "train_data, test_data = train_test_split(df, test_size=0.4, random_state=42)\n",
    "eval_data, test_data = train_test_split(test_data, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"Training data size:\", len(train_data))\n",
    "print(\"Evaluation data size:\", len(eval_data))\n",
    "print(\"Test data size:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821afe8d-f87e-4448-a896-58d96a0ba990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show sample of train data\n",
    "image_data = train_data[train_data['class'] == '/NORMAL'].head(2)\n",
    "for index, row in image_data.iterrows():\n",
    "    img_path = row['dirname'] + '/' + row['filename']\n",
    "    img = plt.imread(img_path)\n",
    "    plt.imshow(img)\n",
    "    plt.title('NORMAL')\n",
    "    plt.show()\n",
    "\n",
    "image_data = train_data[train_data['class'] == '/PNEUMONIA'].head(2)\n",
    "for index, row in image_data.iterrows():\n",
    "    img_path = row['dirname'] + '/' + row['filename']\n",
    "    img = plt.imread(img_path)\n",
    "    plt.imshow(img)\n",
    "    plt.title('PNEUMONIA')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218d31fc-c0df-415e-aff2-353a2b19e505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set image size and batch size\n",
    "img_size = (128, 128)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90081be4-a05e-4154-ae55-14301f6a936a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prefetch the datasets for better performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_data = train_data.prefetch(buffer_size=AUTOTUNE)\n",
    "val_data = eval_data.prefetch(buffer_size=AUTOTUNE)\n",
    "test_data = test_data.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1942a229-7922-43ea-9af5-40120768673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomRotation(0.2),\n",
    "    tf.keras.layers.RandomZoom(0.2),\n",
    "    tf.keras.layers.RandomTranslation(0.1, 0.1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cf8d40-e5e5-4d3e-aed8-7fefbf7367e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained EfficientNetB2 model\n",
    "model = EfficientNetB2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c7676c-0c8c-496f-a92b-d41cfb0b5c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom layers on top of the base model\n",
    "inputs = tf.keras.Input(shape=(128, 128, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = model(x, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "outputs = Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59514d39-2ab8-4c2e-9245-fd27bf897f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final model\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Compile the model with the Adam optimizer, binary crossentropy loss, and additional metrics\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2245cf2c-8e7b-43db-8fa5-2bfbc7d3ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with training data and validate with validation data\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=10,  # Number of epochs for training\n",
    "    validation_data=eval_data,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ModelCheckpoint('model_best.keras', save_best_only=True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa45dc6-b6bb-4860-9321-05277ddc8d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy, test_precision, test_recall = model.evaluate(test_data)\n",
    "\n",
    "# Calculate F1-score using the test precision and test recall\n",
    "test_f1_score = 2 * (test_precision * test_recall) / (test_precision + test_recall)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"Test Precision: {test_precision * 100:.2f}%\")\n",
    "print(f\"Test Recall: {test_recall * 100:.2f}%\")\n",
    "print(f\"Test F1-Score: {test_f1_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f24a3b-3b61-4822-8cb1-1ca8fa9ae93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy and loss over epochs\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ee02d8-9b65-43e7-821d-32e75cd39a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2975d22-85a2-4cf4-84cb-9d0b78e2d426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "predictions = (model.predict(test_dataset) > 0.5).astype(\"int32\")\n",
    "cm = confusion_matrix(np.concatenate([y for x, y in test_dataset], axis=0), predictions)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1567c7-a2e0-4ba3-b4ec-179eb0ac8551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(np.concatenate([y for x, y in test_dataset], axis=0), model.predict(test_dataset))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
